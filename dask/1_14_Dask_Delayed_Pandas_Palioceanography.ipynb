{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelize code with Dask Delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we demonstrate:\n",
    "\n",
    "* A few words about Panda\n",
    "* Read CSV files using Delayed\n",
    "* Read data example\n",
    "* Sequential code: Mean CO3 Per Core\n",
    "* Parallelize the code above using dask delayed\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Authors: NCI Virtual Research Environment Team\n",
    "- Keywords: Dask, Delayed, Pandas, DataFrame\n",
    "- Create Date: 2020-April; Update Date: 2020-April"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisite\n",
    "\n",
    "You can run this notebook on Gadi/VDI (recommended), or on your local computer by downloading [all the CSV example files](git repo). The following modules are needed:\n",
    "\n",
    "* Pandas\n",
    "* Dask\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>NOTE:</b> If you run this notebook on your local computer, make sure that your local computer has multiple cores. Otherwise, your parallel code won't perform any better than sequencial code! \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few words about Pandas\n",
    "\n",
    "Pandas is a an open source library providing high-performance, easy-to-use data structures and data analysis tools. Pandas is particularly suited to the analysis of tabular data, i.e. data that can can go into a table. In other words, if you can imagine the data in an Excel spreadsheet, then Pandas is the tool for the job.\n",
    "\n",
    "Pandas are tools for reading and writing data between in-memory data structures and different formats: CSV and text files, Microsoft Excel, SQL databases, and the fast HDF5 format.\n",
    "\n",
    "Python with pandas is in use in a wide variety of academic and commercial domains, including Finance, Neuroscience, Economics, Statistics, Advertising, Web Analytics, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.6.75.59:8710</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.6.75.59:8752/status' target='_blank'>http://10.6.75.59:8752/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>24</li>\n",
       "  <li><b>Cores: </b>24</li>\n",
       "  <li><b>Memory: </b>103.08 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.6.75.59:8710' processes=24 threads=24, memory=103.08 GB>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create cluster\n",
    "from dask.distributed import Client,LocalCluster\n",
    "client = Client(scheduler_file='scheduler.json')\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting the Dask Client is optional. It will provide a dashboard which is useful to gain insight on the computation.\n",
    "\n",
    "The link to the dashboard will become visible when you create the client below. We recommend having it open on one side of your screen while using your notebook on the other side. This can take some effort to arrange your windows, but seeing them both at the same is very useful when learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale up csv files reading using `delayed` \n",
    "\n",
    "We will apply `delayed` to a real data processing task, albeit a simple one.\n",
    "\n",
    "Consider reading three CSV files with `pd.read_csv` and then measuring their total length. We will consider how you would do this with ordinary Python code, then build a graph for this process using delayed, and finally execute this graph using Dask, for a handy speed-up factor of more than two (there are only three inputs to parallelize over)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CSV/csvfile1.csv', 'CSV/csvfile2.csv', 'CSV/csvfile3.csv']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "from dask import delayed\n",
    "import numpy\n",
    "\n",
    "filenames = sorted(glob('CSV/*.csv'))\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "CPU times: user 4.87 ms, sys: 9.86 ms, total: 14.7 ms\n",
      "Wall time: 13.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# normal, sequential code\n",
    "a = pd.read_csv(filenames[0])\n",
    "b = pd.read_csv(filenames[1])\n",
    "c = pd.read_csv(filenames[2])\n",
    "\n",
    "na = len(a)\n",
    "nb = len(b)\n",
    "nc = len(c)\n",
    "\n",
    "total = sum([na, nb, nc])\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to recreate this graph again using the delayed function on the original Python code. The three functions you want to delay are `pd.read_csv`, `len` and `sum`.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 1.51 ms, total: 1.51 ms\n",
      "Wall time: 1.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Delayed('sum-55c1f334-7733-46dd-9eda-e1fb29a04b13')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# delayed, sequential code\n",
    "delayed_read_csv = delayed(pd.read_csv)\n",
    "a = delayed_read_csv(filenames[0])\n",
    "b = delayed_read_csv(filenames[1])\n",
    "c = delayed_read_csv(filenames[2])\n",
    "\n",
    "delayed_len = delayed(len)\n",
    "na = delayed_len(a)\n",
    "nb = delayed_len(b)\n",
    "nc = delayed_len(c)\n",
    "\n",
    "delayed_sum = delayed(sum)\n",
    "\n",
    "total = delayed_sum([na, nb, nc])\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time print(total.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, repeat this using loops, rather than writing out all the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concise version\n",
    "csvs = [delayed(pd.read_csv)(fn) for fn in filenames]\n",
    "lens = [delayed(len)(csv) for csv in csvs]\n",
    "total = delayed(sum)(lens)\n",
    "%time print(total.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real example\n",
    "\n",
    "### Inspect Data\n",
    "\n",
    "We will use the supplementary data of a paper **Sequestration of carbon in the deep Atlantic during the last glaciation** by Yu. *et. al* published in Nature Geoscience, 2016, doi:10.1038/ngeo2657.\n",
    "\n",
    "I downloaded the data and reorganized it into several CSV files saved under a local directory called `Nature_geo_csv`. This dataset includes lab measurement of PH (i.e., CO3 umol/kg), Oxygen isotopes, Carbon isotopes, and CaCO3 in sediments at different depths of the Ocean Deep Drilling (ODP) cores in the Atlantic Ocean. The name convention for those files are coreID-measurements.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'EW9209-2JPC-PH.csv',\n",
       " 'MD01-2446-O-C.csv',\n",
       " 'MD01-2446-PH.csv',\n",
       " 'MD95-2039-CaCO3.csv',\n",
       " 'MD95-2039-O-C.csv',\n",
       " 'MD95-2039-PH.csv',\n",
       " 'RC13-228-O-C.csv',\n",
       " 'RC13-228-PH.csv',\n",
       " 'RC13-229-O-C.csv',\n",
       " 'RC13-229-PH.csv',\n",
       " 'RC16-59-PH.csv',\n",
       " 'TNO57-21-PH.csv']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "sorted(os.listdir('Nature_geo_csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read one file with pandas.read_csv and compute the mean PH value of a core.\n",
    "\n",
    "We can use `Pandas.read_csv( )` to access csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top</th>\n",
       "      <th>btm</th>\n",
       "      <th>mid</th>\n",
       "      <th>age</th>\n",
       "      <th>Cw B/Ca</th>\n",
       "      <th>CO3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>815</td>\n",
       "      <td>816</td>\n",
       "      <td>815.5</td>\n",
       "      <td>51.9</td>\n",
       "      <td>123.4</td>\n",
       "      <td>83.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>853</td>\n",
       "      <td>854</td>\n",
       "      <td>853.5</td>\n",
       "      <td>54.6</td>\n",
       "      <td>128.8</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>916</td>\n",
       "      <td>917</td>\n",
       "      <td>916.5</td>\n",
       "      <td>60.7</td>\n",
       "      <td>114.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>925</td>\n",
       "      <td>926</td>\n",
       "      <td>925.5</td>\n",
       "      <td>61.4</td>\n",
       "      <td>113.3</td>\n",
       "      <td>74.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>936</td>\n",
       "      <td>937</td>\n",
       "      <td>936.5</td>\n",
       "      <td>62.3</td>\n",
       "      <td>111.3</td>\n",
       "      <td>72.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   top  btm    mid   age  Cw B/Ca   CO3\n",
       "0  815  816  815.5  51.9    123.4  83.3\n",
       "1  853  854  853.5  54.6    128.8  88.0\n",
       "2  916  917  916.5  60.7    114.0  75.0\n",
       "3  925  926  925.5  61.4    113.3  74.5\n",
       "4  936  937  936.5  62.3    111.3  72.7"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# skip the first two lines\n",
    "# line1: core name\n",
    "# line2: units of the measurement in each column\n",
    "df = pd.read_csv(\"Nature_geo_csv/TNO57-21-PH.csv\",skiprows=2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "top          int64\n",
       "btm          int64\n",
       "mid        float64\n",
       "age        float64\n",
       "Cw B/Ca    float64\n",
       "CO3        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the schema?\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "top        1092.583333\n",
       "btm        1093.604167\n",
       "mid        1093.093750\n",
       "age          73.637500\n",
       "Cw B/Ca     125.895833\n",
       "CO3          85.506250\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the mean value of each column\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can get a single column as a Series using python's getitem syntax on the DataFrame object.\n",
    "df['CO3']\n",
    "\n",
    "# or specify one column to get the mean of that data series only\n",
    "df.CO3.mean()\n",
    "\n",
    "# get number of data points\n",
    "import numpy as np\n",
    "np.size(df['CO3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential code: Mean CO3 Per Core\n",
    "\n",
    "The above cell computes the mean departure delay per-airport for one year. Here we expand that to all years using a sequential for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nature_geo_csv/EW9209-2JPC-PH.csv',\n",
       " 'Nature_geo_csv/MD01-2446-PH.csv',\n",
       " 'Nature_geo_csv/MD95-2039-PH.csv',\n",
       " 'Nature_geo_csv/RC13-228-PH.csv',\n",
       " 'Nature_geo_csv/RC13-229-PH.csv',\n",
       " 'Nature_geo_csv/RC16-59-PH.csv',\n",
       " 'Nature_geo_csv/TNO57-21-PH.csv']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "filenames = sorted(glob('Nature_geo_csv/*-PH.csv'))\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.4 ms, sys: 3.62 ms, total: 23.1 ms\n",
      "Wall time: 23.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "means = []\n",
    "counts = []\n",
    "for fn in filenames:\n",
    "    # Read in file\n",
    "    df = pd.read_csv(fn,skiprows=2)\n",
    "    \n",
    "    # Get the mean CO3 for each core\n",
    "    mean_CO3_each = df.CO3.mean()\n",
    "\n",
    "    # Count how many data points in each core\n",
    "    count = np.size(df['CO3'])\n",
    "\n",
    "    # Save the intermediates\n",
    "    means.append(mean_CO3_each)\n",
    "    counts.append(count)\n",
    "\n",
    "# Combine intermediates to get total mean-delay-per-origin\n",
    "mean_CO3 = np.mean(means)\n",
    "n_dpoints = sum(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[92.66666666666667,\n",
       " 97.8157894736842,\n",
       " 106.03571428571429,\n",
       " 90.16,\n",
       " 80.31818181818181,\n",
       " 94.51515151515152,\n",
       " 85.50625000000002]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_CO3\n",
    "n_dpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelize the code above\n",
    "\n",
    "Use dask.delayed to parallelize the code above. Some extra things you will need to know.\n",
    "\n",
    "Methods and attribute access on delayed objects work automatically, so if you have a delayed object you can perform normal arithmetic, slicing, and method calls on it and it will produce the correct delayed calls.\n",
    "\n",
    "```\n",
    "x = delayed(np.arange)(10)\n",
    "y = (x + 1)[::2].sum()  # everything here was delayed\n",
    "```\n",
    "\n",
    "Calling the `.compute()` method works well when you have a single output. When you have multiple outputs you might want to use the `dask.compute` function:\n",
    "\n",
    "```\n",
    "x = delayed(np.arange)(10)\n",
    "y = x ** 2\n",
    "min_, max_ = compute(y.min(), y.max())\n",
    "min_, max_\n",
    "(0, 81)\n",
    "```\n",
    "This way Dask can share the intermediate values (like `y = x**2`)\n",
    "So your goal is to parallelize the code above (which has been copied below) using dask.delayed. You may also want to visualize a bit of the computation to see if youâ€™re doing it correctly. This is just one way of using `delayed`, there are several ways to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import compute\n",
    "from dask import delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "means = []\n",
    "counts = []\n",
    "for fn in filenames:\n",
    "    # Read in file\n",
    "    df = delayed(pd.read_csv)(fn,skiprows=2)\n",
    "    \n",
    "    # Get the mean CO3 for each core\n",
    "    mean_CO3_each = df.CO3.mean()\n",
    "\n",
    "    # Count how many data points in each core\n",
    "    count = np.size(df['CO3'])\n",
    "\n",
    "    # Save the intermediates\n",
    "    means.append(mean_CO3_each)\n",
    "    counts.append(count)\n",
    "\n",
    "# Compute the intermediates\n",
    "means, counts = compute(means, counts)\n",
    "\n",
    "# Combine intermediates to get total mean-delay-per-origin\n",
    "#mean_CO31 = np.mean(means1)\n",
    "#n_dpoints = sum(counts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.43110767991409"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_CO3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the client\n",
    "\n",
    "Before moving on to the next exercise, make sure to close your client or stop this kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "This example shows how Pandas work with multiple tabular datasets efficiently using dask delayed feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "https://tutorial.dask.org"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
