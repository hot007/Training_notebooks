{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Chunking with Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we demonstrate:\n",
    "\n",
    "* Xarray + Dask\n",
    "* NetCDF file Chunks versus Dask Chunks\n",
    "* chunk shapes\n",
    "\n",
    "The following material uses Coupled Model Intercomparison Project (CMIP6) collections. Please visit data collection [catalogue](https://geonetwork.nci.org.au/geonetwork/srv/eng/catalog.search#/metadata/f6600_2266_8675_3563) and [CMIP6 terms of use](https://pcmdi.llnl.gov/CMIP6/TermsOfUse/TermsOfUse6-1.html) for more information. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Authors: NCI Virtual Research Environment Team\n",
    "- Keywords: CMIP6, Xarray, Dask, Diagnostics\n",
    "- Create Date: 2019-June; Update Date: 2020-May"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisite\n",
    "\n",
    "You need to run this notebook on Gadi/VDI (recommended), or on your local computer if CMIP6 data can be accessed from remote links via data services. The following modules are needed:\n",
    "\n",
    "* Xarray\n",
    "* Dask\n",
    "* NetCDF\n",
    "\n",
    "You also need to be a member of the following data project to access the data or through [NCI's data service](http://dapds00.nci.org.au/thredds/catalog.html) if the data is published:\n",
    "* oi10\n",
    "\n",
    "You can request to join the project through [NCI's user account management system](https://my.nci.org.au). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import netCDF4 as nc\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting the Dask Client is optional. It will provide a dashboard which is useful to gain insight on the computation.\n",
    "\n",
    "The link to the dashboard will become visible when you create the client below. We recommend having it open on one side of your screen while using your notebook on the other side. This can take some effort to arrange your windows, but seeing them both at the same is very useful when learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Client: 'tcp://10.6.52.21:8731' processes=32 threads=32, memory=68.72 GB>\n"
     ]
    }
   ],
   "source": [
    "# Create cluster\n",
    "from dask.distributed import Client,LocalCluster\n",
    "client = Client(scheduler_file='scheduler.json')\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "We will use percipitation data update of RCP8.5 based on SSP5 from GFDL-CM4 ensembles in this example, let's have a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netcdf pr_day_GFDL-CM4_ssp585_r1i1p1f1_gr1_20150101-20341231 {\n",
      "dimensions:\n",
      "\tlat = 180 ;\n",
      "\tbnds = 2 ;\n",
      "\tlon = 288 ;\n",
      "\ttime = UNLIMITED ; // (7300 currently)\n",
      "variables:\n",
      "\tdouble lat(lat) ;\n",
      "\t\tlat:long_name = \"latitude\" ;\n",
      "\t\tlat:units = \"degrees_north\" ;\n",
      "\t\tlat:axis = \"Y\" ;\n",
      "\t\tlat:bounds = \"lat_bnds\" ;\n",
      "\t\tlat:standard_name = \"latitude\" ;\n",
      "\t\tlat:cell_methods = \"time: point\" ;\n",
      "\t\tlat:_Storage = \"chunked\" ;\n",
      "\t\tlat:_ChunkSizes = 180 ;\n",
      "\t\tlat:_DeflateLevel = 2 ;\n",
      "\t\tlat:_Shuffle = \"true\" ;\n",
      "\t\tlat:_Endianness = \"little\" ;\n",
      "\tdouble lat_bnds(lat, bnds) ;\n",
      "\t\tlat_bnds:long_name = \"latitude bounds\" ;\n",
      "\t\tlat_bnds:units = \"degrees_north\" ;\n",
      "\t\tlat_bnds:axis = \"Y\" ;\n",
      "\t\tlat_bnds:_Storage = \"chunked\" ;\n",
      "\t\tlat_bnds:_ChunkSizes = 180, 2 ;\n",
      "\t\tlat_bnds:_DeflateLevel = 2 ;\n",
      "\t\tlat_bnds:_Shuffle = \"true\" ;\n",
      "\t\tlat_bnds:_Endianness = \"little\" ;\n",
      "\tdouble lon(lon) ;\n",
      "\t\tlon:long_name = \"longitude\" ;\n",
      "\t\tlon:units = \"degrees_east\" ;\n",
      "\t\tlon:axis = \"X\" ;\n",
      "\t\tlon:bounds = \"lon_bnds\" ;\n",
      "\t\tlon:standard_name = \"longitude\" ;\n",
      "\t\tlon:cell_methods = \"time: point\" ;\n",
      "\t\tlon:_Storage = \"chunked\" ;\n",
      "\t\tlon:_ChunkSizes = 288 ;\n",
      "\t\tlon:_DeflateLevel = 2 ;\n",
      "\t\tlon:_Shuffle = \"true\" ;\n",
      "\t\tlon:_Endianness = \"little\" ;\n",
      "\tdouble lon_bnds(lon, bnds) ;\n",
      "\t\tlon_bnds:long_name = \"longitude bounds\" ;\n",
      "\t\tlon_bnds:units = \"degrees_east\" ;\n",
      "\t\tlon_bnds:axis = \"X\" ;\n",
      "\t\tlon_bnds:_Storage = \"chunked\" ;\n",
      "\t\tlon_bnds:_ChunkSizes = 288, 2 ;\n",
      "\t\tlon_bnds:_DeflateLevel = 2 ;\n",
      "\t\tlon_bnds:_Shuffle = \"true\" ;\n",
      "\t\tlon_bnds:_Endianness = \"little\" ;\n",
      "\tfloat pr(time, lat, lon) ;\n",
      "\t\tpr:long_name = \"Precipitation\" ;\n",
      "\t\tpr:units = \"kg m-2 s-1\" ;\n",
      "\t\tpr:missing_value = 1.e+20f ;\n",
      "\t\tpr:_FillValue = 1.e+20f ;\n",
      "\t\tpr:cell_methods = \"area: time: mean\" ;\n",
      "\t\tpr:cell_measures = \"area: areacella\" ;\n",
      "\t\tpr:standard_name = \"precipitation_flux\" ;\n",
      "\t\tpr:interp_method = \"conserve_order1\" ;\n",
      "\t\tpr:original_name = \"pr\" ;\n",
      "\t\tpr:_Storage = \"chunked\" ;\n",
      "\t\tpr:_ChunkSizes = 1, 180, 288 ;\n",
      "\t\tpr:_DeflateLevel = 2 ;\n",
      "\t\tpr:_Shuffle = \"true\" ;\n",
      "\t\tpr:_Endianness = \"little\" ;\n",
      "\tdouble time(time) ;\n",
      "\t\ttime:long_name = \"time\" ;\n",
      "\t\ttime:units = \"days since 1850-01-01 00:00:00\" ;\n",
      "\t\ttime:axis = \"T\" ;\n",
      "\t\ttime:calendar_type = \"noleap\" ;\n",
      "\t\ttime:calendar = \"noleap\" ;\n",
      "\t\ttime:bounds = \"time_bnds\" ;\n",
      "\t\ttime:standard_name = \"time\" ;\n",
      "\t\ttime:description = \"Temporal mean\" ;\n",
      "\t\ttime:_Storage = \"chunked\" ;\n",
      "\t\ttime:_ChunkSizes = 1 ;\n",
      "\t\ttime:_DeflateLevel = 2 ;\n",
      "\t\ttime:_Shuffle = \"true\" ;\n",
      "\t\ttime:_Endianness = \"little\" ;\n",
      "\tdouble time_bnds(time, bnds) ;\n",
      "\t\ttime_bnds:long_name = \"time axis boundaries\" ;\n",
      "\t\ttime_bnds:units = \"days since 1850-01-01 00:00:00\" ;\n",
      "\t\ttime_bnds:_Storage = \"chunked\" ;\n",
      "\t\ttime_bnds:_ChunkSizes = 1, 2 ;\n",
      "\t\ttime_bnds:_DeflateLevel = 2 ;\n",
      "\t\ttime_bnds:_Shuffle = \"true\" ;\n",
      "\t\ttime_bnds:_Endianness = \"little\" ;\n",
      "\n",
      "// global attributes:\n",
      "\t\t:external_variables = \"areacella\" ;\n",
      "\t\t:history = \"File was processed by fremetar (GFDL analog of CMOR). TripleID: [exper_id_8FFywjr5HC,realiz_id_Lda2LtjE2s,run_id_Dj7oSa1Fj7]\" ;\n",
      "\t\t:table_id = \"day\" ;\n",
      "\t\t:activity_id = \"ScenarioMIP\" ;\n",
      "\t\t:branch_method = \"standard\" ;\n",
      "\t\t:branch_time_in_child = 0. ;\n",
      "\t\t:comment = \"<null ref>\" ;\n",
      "\t\t:contact = \"gfdl.climate.model.info@noaa.gov\" ;\n",
      "\t\t:Conventions = \"CF-1.7 CMIP-6.0 UGRID-1.0\" ;\n",
      "\t\t:creation_date = \"2019-03-18T15:13:56Z\" ;\n",
      "\t\t:data_specs_version = \"01.00.27\" ;\n",
      "\t\t:experiment = \"update of RCP8.5 based on SSP5\" ;\n",
      "\t\t:experiment_id = \"ssp585\" ;\n",
      "\t\t:forcing_index = 1 ;\n",
      "\t\t:frequency = \"day\" ;\n",
      "\t\t:further_info_url = \"https://furtherinfo.es-doc.org/CMIP6.NOAA-GFDL.GFDL-CM4.ssp585.none.r1i1p1f1\" ;\n",
      "\t\t:grid = \"atmos data regridded from Cubed-sphere (c96) to 180,288; interpolation method: conserve_order1\" ;\n",
      "\t\t:grid_label = \"gr1\" ;\n",
      "\t\t:initialization_index = 1 ;\n",
      "\t\t:institution = \"National Oceanic and Atmospheric Administration, Geophysical Fluid Dynamics Laboratory, Princeton, NJ 08540, USA\" ;\n",
      "\t\t:institution_id = \"NOAA-GFDL\" ;\n",
      "\t\t:license = \"CMIP6 model data produced by NOAA-GFDL is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License (https://creativecommons.org/licenses/). Consult https://pcmdi.llnl.gov/CMIP6/TermsOfUse for terms of use governing CMIP6 output, including citation requirements and proper acknowledgment. Further information about this data, including some limitations, can be found via the further_info_url (recorded as a global attribute in this file). The data producers and data providers make no warranty, either express or implied, including, but not limited to, warranties of merchantability and fitness for a particular purpose. All liabilities arising from the supply of the information (including any liability arising in negligence) are excluded to the fullest extent permitted by law.\" ;\n",
      "\t\t:mip_era = \"CMIP6\" ;\n",
      "\t\t:nominal_resolution = \"100 km\" ;\n",
      "\t\t:parent_activity_id = \"CMIP\" ;\n",
      "\t\t:parent_experiment_id = \"historical\" ;\n",
      "\t\t:parent_mip_era = \"CMIP6\" ;\n",
      "\t\t:parent_source_id = \"GFDL-CM4\" ;\n",
      "\t\t:parent_variant_label = \"r1i1p1f1\" ;\n",
      "\t\t:physics_index = 1 ;\n",
      "\t\t:product = \"model-output\" ;\n",
      "\t\t:realization_index = 1 ;\n",
      "\t\t:realm = \"atmos\" ;\n",
      "\t\t:source = \"GFDL-CM4 (2018): \\n\",\n",
      "\t\t\t\"aerosol: interactive\\n\",\n",
      "\t\t\t\"atmos: GFDL-AM4.0.1 (Cubed-sphere (c96) - 1 degree nominal horizontal resolution; 360 x 180 longitude/latitude; 33 levels; top level 1 hPa)\\n\",\n",
      "\t\t\t\"atmosChem: fast chemistry, aerosol only\\n\",\n",
      "\t\t\t\"land: GFDL-LM4.0.1 (1 degree nominal horizontal resolution; 360 x 180 longitude/latitude; 20 levels; bot level 10m); land:Veg:unnamed (dynamic vegetation, dynamic land use); land:Hydro:unnamed (soil water and ice, multi-layer snow, rivers and lakes)\\n\",\n",
      "\t\t\t\"landIce: GFDL-LM4.0.1\\n\",\n",
      "\t\t\t\"ocean: GFDL-OM4p25 (GFDL-MOM6, tripolar - nominal 0.25 deg; 1440 x 1080 longitude/latitude; 75 levels; top grid cell 0-2 m)\\n\",\n",
      "\t\t\t\"ocnBgchem: GFDL-BLINGv2\\n\",\n",
      "\t\t\t\"seaIce: GFDL-SIM4p25 (GFDL-SIS2.0, tripolar - nominal 0.25 deg; 1440 x 1080 longitude/latitude; 5 layers; 5 thickness categories)\\n\",\n",
      "\t\t\t\"(GFDL ID: 2019_0186)\" ;\n",
      "\t\t:source_id = \"GFDL-CM4\" ;\n",
      "\t\t:source_type = \"AOGCM\" ;\n",
      "\t\t:sub_experiment = \"none\" ;\n",
      "\t\t:sub_experiment_id = \"none\" ;\n",
      "\t\t:title = \"NOAA GFDL GFDL-CM4 model output prepared for CMIP6 update of RCP8.5 based on SSP5\" ;\n",
      "\t\t:tracking_id = \"hdl:21.14100/ad8c930c-124f-4b82-98b2-98cc4236ba25\" ;\n",
      "\t\t:variable_id = \"pr\" ;\n",
      "\t\t:variant_info = \"N/A\" ;\n",
      "\t\t:references = \"see further_info_url attribute\" ;\n",
      "\t\t:variant_label = \"r1i1p1f1\" ;\n",
      "\t\t:branch_time_in_parent = 60225. ;\n",
      "\t\t:parent_time_units = \"days since 1850-1-1\" ;\n",
      "\t\t:_SuperblockVersion = 2 ;\n",
      "\t\t:_IsNetcdf4 = 1 ;\n",
      "\t\t:_Format = \"netCDF-4 classic model\" ;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!ncdump -hst '/g/data/oi10/replicas/CMIP6/ScenarioMIP/NOAA-GFDL/GFDL-CM4/ssp585/r1i1p1f1/day/pr/gr1/v20180701/pr_day_GFDL-CM4_ssp585_r1i1p1f1_gr1_20150101-20341231.nc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xarray + Dask\n",
    "\n",
    "Xarray can automatically wrap its data in dask arrays. This capability turns xarray into an extremely powerful tool for Big Data earth science\n",
    "\n",
    "To see this in action, we will download a fairly large dataset to analyze. We use xarray's `open_mfdataset` allows multiple files to be opened simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr_day_GFDL-CM4_ssp585_r1i1p1f1_gr1_20150101-20341231.nc\n",
      "pr_day_GFDL-CM4_ssp585_r1i1p1f1_gr1_20350101-20541231.nc\n",
      "pr_day_GFDL-CM4_ssp585_r1i1p1f1_gr1_20550101-20741231.nc\n",
      "pr_day_GFDL-CM4_ssp585_r1i1p1f1_gr1_20750101-20941231.nc\n",
      "pr_day_GFDL-CM4_ssp585_r1i1p1f1_gr1_20950101-21001231.nc\n"
     ]
    }
   ],
   "source": [
    "!ls /g/data/oi10/replicas/CMIP6/ScenarioMIP/NOAA-GFDL/GFDL-CM4/ssp585/r1i1p1f1/day/pr/gr1/v20180701\n",
    "path = '/g/data/oi10/replicas/CMIP6/ScenarioMIP/NOAA-GFDL/GFDL-CM4/ssp585/r1i1p1f1/day/pr/gr1/v20180701/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:    (bnds: 2, lat: 180, lon: 288, time: 31390)\n",
       "Coordinates:\n",
       "  * lon        (lon) float64 0.625 1.875 3.125 4.375 ... 355.6 356.9 358.1 359.4\n",
       "  * lat        (lat) float64 -89.5 -88.5 -87.5 -86.5 ... 86.5 87.5 88.5 89.5\n",
       "  * time       (time) object 2015-01-01 12:00:00 ... 2100-12-31 12:00:00\n",
       "Dimensions without coordinates: bnds\n",
       "Data variables:\n",
       "    lat_bnds   (time, lat, bnds) float64 dask.array&lt;chunksize=(7300, 180, 2), meta=np.ndarray&gt;\n",
       "    lon_bnds   (time, lon, bnds) float64 dask.array&lt;chunksize=(7300, 288, 2), meta=np.ndarray&gt;\n",
       "    pr         (time, lat, lon) float32 dask.array&lt;chunksize=(7300, 180, 288), meta=np.ndarray&gt;\n",
       "    time_bnds  (time, bnds) object dask.array&lt;chunksize=(7300, 2), meta=np.ndarray&gt;\n",
       "Attributes:\n",
       "    external_variables:     areacella\n",
       "    history:                File was processed by fremetar (GFDL analog of CM...\n",
       "    table_id:               day\n",
       "    activity_id:            ScenarioMIP\n",
       "    branch_method:          standard\n",
       "    branch_time_in_child:   0.0\n",
       "    comment:                &lt;null ref&gt;\n",
       "    contact:                gfdl.climate.model.info@noaa.gov\n",
       "    Conventions:            CF-1.7 CMIP-6.0 UGRID-1.0\n",
       "    creation_date:          2019-03-18T15:13:56Z\n",
       "    data_specs_version:     01.00.27\n",
       "    experiment:             update of RCP8.5 based on SSP5\n",
       "    experiment_id:          ssp585\n",
       "    forcing_index:          1\n",
       "    frequency:              day\n",
       "    further_info_url:       https://furtherinfo.es-doc.org/CMIP6.NOAA-GFDL.GF...\n",
       "    grid:                   atmos data regridded from Cubed-sphere (c96) to 1...\n",
       "    grid_label:             gr1\n",
       "    initialization_index:   1\n",
       "    institution:            National Oceanic and Atmospheric Administration, ...\n",
       "    institution_id:         NOAA-GFDL\n",
       "    license:                CMIP6 model data produced by NOAA-GFDL is license...\n",
       "    mip_era:                CMIP6\n",
       "    nominal_resolution:     100 km\n",
       "    parent_activity_id:     CMIP\n",
       "    parent_experiment_id:   historical\n",
       "    parent_mip_era:         CMIP6\n",
       "    parent_source_id:       GFDL-CM4\n",
       "    parent_variant_label:   r1i1p1f1\n",
       "    physics_index:          1\n",
       "    product:                model-output\n",
       "    realization_index:      1\n",
       "    realm:                  atmos\n",
       "    source:                 GFDL-CM4 (2018): \\naerosol: interactive\\natmos: G...\n",
       "    source_id:              GFDL-CM4\n",
       "    source_type:            AOGCM\n",
       "    sub_experiment:         none\n",
       "    sub_experiment_id:      none\n",
       "    title:                  NOAA GFDL GFDL-CM4 model output prepared for CMIP...\n",
       "    tracking_id:            hdl:21.14100/ad8c930c-124f-4b82-98b2-98cc4236ba25\n",
       "    variable_id:            pr\n",
       "    variant_info:           N/A\n",
       "    references:             see further_info_url attribute\n",
       "    variant_label:          r1i1p1f1\n",
       "    branch_time_in_parent:  60225.0\n",
       "    parent_time_units:      days since 1850-1-1</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (bnds: 2, lat: 180, lon: 288, time: 31390)\n",
       "Coordinates:\n",
       "  * lon        (lon) float64 0.625 1.875 3.125 4.375 ... 355.6 356.9 358.1 359.4\n",
       "  * lat        (lat) float64 -89.5 -88.5 -87.5 -86.5 ... 86.5 87.5 88.5 89.5\n",
       "  * time       (time) object 2015-01-01 12:00:00 ... 2100-12-31 12:00:00\n",
       "Dimensions without coordinates: bnds\n",
       "Data variables:\n",
       "    lat_bnds   (time, lat, bnds) float64 dask.array<chunksize=(7300, 180, 2), meta=np.ndarray>\n",
       "    lon_bnds   (time, lon, bnds) float64 dask.array<chunksize=(7300, 288, 2), meta=np.ndarray>\n",
       "    pr         (time, lat, lon) float32 dask.array<chunksize=(7300, 180, 288), meta=np.ndarray>\n",
       "    time_bnds  (time, bnds) object dask.array<chunksize=(7300, 2), meta=np.ndarray>\n",
       "Attributes:\n",
       "    external_variables:     areacella\n",
       "    history:                File was processed by fremetar (GFDL analog of CM...\n",
       "    table_id:               day\n",
       "    activity_id:            ScenarioMIP\n",
       "    branch_method:          standard\n",
       "    branch_time_in_child:   0.0\n",
       "    comment:                <null ref>\n",
       "    contact:                gfdl.climate.model.info@noaa.gov\n",
       "    Conventions:            CF-1.7 CMIP-6.0 UGRID-1.0\n",
       "    creation_date:          2019-03-18T15:13:56Z\n",
       "    data_specs_version:     01.00.27\n",
       "    experiment:             update of RCP8.5 based on SSP5\n",
       "    experiment_id:          ssp585\n",
       "    forcing_index:          1\n",
       "    frequency:              day\n",
       "    further_info_url:       https://furtherinfo.es-doc.org/CMIP6.NOAA-GFDL.GF...\n",
       "    grid:                   atmos data regridded from Cubed-sphere (c96) to 1...\n",
       "    grid_label:             gr1\n",
       "    initialization_index:   1\n",
       "    institution:            National Oceanic and Atmospheric Administration, ...\n",
       "    institution_id:         NOAA-GFDL\n",
       "    license:                CMIP6 model data produced by NOAA-GFDL is license...\n",
       "    mip_era:                CMIP6\n",
       "    nominal_resolution:     100 km\n",
       "    parent_activity_id:     CMIP\n",
       "    parent_experiment_id:   historical\n",
       "    parent_mip_era:         CMIP6\n",
       "    parent_source_id:       GFDL-CM4\n",
       "    parent_variant_label:   r1i1p1f1\n",
       "    physics_index:          1\n",
       "    product:                model-output\n",
       "    realization_index:      1\n",
       "    realm:                  atmos\n",
       "    source:                 GFDL-CM4 (2018): \\naerosol: interactive\\natmos: G...\n",
       "    source_id:              GFDL-CM4\n",
       "    source_type:            AOGCM\n",
       "    sub_experiment:         none\n",
       "    sub_experiment_id:      none\n",
       "    title:                  NOAA GFDL GFDL-CM4 model output prepared for CMIP...\n",
       "    tracking_id:            hdl:21.14100/ad8c930c-124f-4b82-98b2-98cc4236ba25\n",
       "    variable_id:            pr\n",
       "    variant_info:           N/A\n",
       "    references:             see further_info_url attribute\n",
       "    variant_label:          r1i1p1f1\n",
       "    branch_time_in_parent:  60225.0\n",
       "    parent_time_units:      days since 1850-1-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_ssp585 = xr.open_mfdataset(path, combine='by_coords')\n",
    "f_ssp585"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>NOTE:</b> the values are not displayed, since that would trigger computation.. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunks\n",
    "\n",
    "Notice that it says:`pr(time, lat, lon) float32 dask.array<chunksize=(7300, 180, 288), meta=np.ndarray>`. There is now the `chunksize` component. The data array also become an dask array.\n",
    "\n",
    "The chunking of the array comes from the integration of Dask with xarray. Dask (see: https://docs.dask.org/en/latest/) is a library for parallel computing. Dask divides the data array into small pieces called \"chunks\", with each chunk designed to be small enough to fit into memory. \n",
    "\n",
    "The file itself may be already chunked. Filesystem chunking is available in netCDF-4 and HDF5 datasets. CMIP6 data should all be netCDF-4 and include some form of chunking on the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netcdf pr_day_GFDL-CM4_ssp585_r1i1p1f1_gr1_20150101-20341231 {\n",
      "dimensions:\n",
      "\tlat = 180 ;\n",
      "\tbnds = 2 ;\n",
      "\tlon = 288 ;\n",
      "\ttime = UNLIMITED ; // (7300 currently)\n",
      "variables:\n",
      "\tdouble lat(lat) ;\n",
      "\t\tlat:long_name = \"latitude\" ;\n",
      "\t\tlat:units = \"degrees_north\" ;\n",
      "\t\tlat:axis = \"Y\" ;\n",
      "\t\tlat:bounds = \"lat_bnds\" ;\n",
      "\t\tlat:standard_name = \"latitude\" ;\n",
      "\t\tlat:cell_methods = \"time: point\" ;\n",
      "\t\tlat:_Storage = \"chunked\" ;\n",
      "\t\tlat:_ChunkSizes = 180 ;\n",
      "\t\tlat:_DeflateLevel = 2 ;\n",
      "\t\tlat:_Shuffle = \"true\" ;\n",
      "\t\tlat:_Endianness = \"little\" ;\n",
      "\tdouble lat_bnds(lat, bnds) ;\n",
      "\t\tlat_bnds:long_name = \"latitude bounds\" ;\n",
      "\t\tlat_bnds:units = \"degrees_north\" ;\n",
      "\t\tlat_bnds:axis = \"Y\" ;\n",
      "\t\tlat_bnds:_Storage = \"chunked\" ;\n",
      "\t\tlat_bnds:_ChunkSizes = 180, 2 ;\n",
      "\t\tlat_bnds:_DeflateLevel = 2 ;\n",
      "\t\tlat_bnds:_Shuffle = \"true\" ;\n",
      "\t\tlat_bnds:_Endianness = \"little\" ;\n",
      "\tdouble lon(lon) ;\n",
      "\t\tlon:long_name = \"longitude\" ;\n",
      "\t\tlon:units = \"degrees_east\" ;\n",
      "\t\tlon:axis = \"X\" ;\n",
      "\t\tlon:bounds = \"lon_bnds\" ;\n",
      "\t\tlon:standard_name = \"longitude\" ;\n",
      "\t\tlon:cell_methods = \"time: point\" ;\n",
      "\t\tlon:_Storage = \"chunked\" ;\n",
      "\t\tlon:_ChunkSizes = 288 ;\n",
      "\t\tlon:_DeflateLevel = 2 ;\n",
      "\t\tlon:_Shuffle = \"true\" ;\n",
      "\t\tlon:_Endianness = \"little\" ;\n",
      "\tdouble lon_bnds(lon, bnds) ;\n",
      "\t\tlon_bnds:long_name = \"longitude bounds\" ;\n",
      "\t\tlon_bnds:units = \"degrees_east\" ;\n",
      "\t\tlon_bnds:axis = \"X\" ;\n",
      "\t\tlon_bnds:_Storage = \"chunked\" ;\n",
      "\t\tlon_bnds:_ChunkSizes = 288, 2 ;\n",
      "\t\tlon_bnds:_DeflateLevel = 2 ;\n",
      "\t\tlon_bnds:_Shuffle = \"true\" ;\n",
      "\t\tlon_bnds:_Endianness = \"little\" ;\n",
      "\tfloat pr(time, lat, lon) ;\n",
      "\t\tpr:long_name = \"Precipitation\" ;\n",
      "\t\tpr:units = \"kg m-2 s-1\" ;\n",
      "\t\tpr:missing_value = 1.e+20f ;\n",
      "\t\tpr:_FillValue = 1.e+20f ;\n",
      "\t\tpr:cell_methods = \"area: time: mean\" ;\n",
      "\t\tpr:cell_measures = \"area: areacella\" ;\n",
      "\t\tpr:standard_name = \"precipitation_flux\" ;\n",
      "\t\tpr:interp_method = \"conserve_order1\" ;\n",
      "\t\tpr:original_name = \"pr\" ;\n",
      "\t\tpr:_Storage = \"chunked\" ;\n",
      "\t\tpr:_ChunkSizes = 1, 180, 288 ;\n",
      "\t\tpr:_DeflateLevel = 2 ;\n",
      "\t\tpr:_Shuffle = \"true\" ;\n",
      "\t\tpr:_Endianness = \"little\" ;\n",
      "\tdouble time(time) ;\n",
      "\t\ttime:long_name = \"time\" ;\n",
      "\t\ttime:units = \"days since 1850-01-01 00:00:00\" ;\n",
      "\t\ttime:axis = \"T\" ;\n",
      "\t\ttime:calendar_type = \"noleap\" ;\n",
      "\t\ttime:calendar = \"noleap\" ;\n",
      "\t\ttime:bounds = \"time_bnds\" ;\n",
      "\t\ttime:standard_name = \"time\" ;\n",
      "\t\ttime:description = \"Temporal mean\" ;\n",
      "\t\ttime:_Storage = \"chunked\" ;\n",
      "\t\ttime:_ChunkSizes = 1 ;\n",
      "\t\ttime:_DeflateLevel = 2 ;\n",
      "\t\ttime:_Shuffle = \"true\" ;\n",
      "\t\ttime:_Endianness = \"little\" ;\n",
      "\tdouble time_bnds(time, bnds) ;\n",
      "\t\ttime_bnds:long_name = \"time axis boundaries\" ;\n",
      "\t\ttime_bnds:units = \"days since 1850-01-01 00:00:00\" ;\n",
      "\t\ttime_bnds:_Storage = \"chunked\" ;\n",
      "\t\ttime_bnds:_ChunkSizes = 1, 2 ;\n",
      "\t\ttime_bnds:_DeflateLevel = 2 ;\n",
      "\t\ttime_bnds:_Shuffle = \"true\" ;\n",
      "\t\ttime_bnds:_Endianness = \"little\" ;\n",
      "\n",
      "// global attributes:\n",
      "\t\t:external_variables = \"areacella\" ;\n",
      "\t\t:history = \"File was processed by fremetar (GFDL analog of CMOR). TripleID: [exper_id_8FFywjr5HC,realiz_id_Lda2LtjE2s,run_id_Dj7oSa1Fj7]\" ;\n",
      "\t\t:table_id = \"day\" ;\n",
      "\t\t:activity_id = \"ScenarioMIP\" ;\n",
      "\t\t:branch_method = \"standard\" ;\n",
      "\t\t:branch_time_in_child = 0. ;\n",
      "\t\t:comment = \"<null ref>\" ;\n",
      "\t\t:contact = \"gfdl.climate.model.info@noaa.gov\" ;\n",
      "\t\t:Conventions = \"CF-1.7 CMIP-6.0 UGRID-1.0\" ;\n",
      "\t\t:creation_date = \"2019-03-18T15:13:56Z\" ;\n",
      "\t\t:data_specs_version = \"01.00.27\" ;\n",
      "\t\t:experiment = \"update of RCP8.5 based on SSP5\" ;\n",
      "\t\t:experiment_id = \"ssp585\" ;\n",
      "\t\t:forcing_index = 1 ;\n",
      "\t\t:frequency = \"day\" ;\n",
      "\t\t:further_info_url = \"https://furtherinfo.es-doc.org/CMIP6.NOAA-GFDL.GFDL-CM4.ssp585.none.r1i1p1f1\" ;\n",
      "\t\t:grid = \"atmos data regridded from Cubed-sphere (c96) to 180,288; interpolation method: conserve_order1\" ;\n",
      "\t\t:grid_label = \"gr1\" ;\n",
      "\t\t:initialization_index = 1 ;\n",
      "\t\t:institution = \"National Oceanic and Atmospheric Administration, Geophysical Fluid Dynamics Laboratory, Princeton, NJ 08540, USA\" ;\n",
      "\t\t:institution_id = \"NOAA-GFDL\" ;\n",
      "\t\t:license = \"CMIP6 model data produced by NOAA-GFDL is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License (https://creativecommons.org/licenses/). Consult https://pcmdi.llnl.gov/CMIP6/TermsOfUse for terms of use governing CMIP6 output, including citation requirements and proper acknowledgment. Further information about this data, including some limitations, can be found via the further_info_url (recorded as a global attribute in this file). The data producers and data providers make no warranty, either express or implied, including, but not limited to, warranties of merchantability and fitness for a particular purpose. All liabilities arising from the supply of the information (including any liability arising in negligence) are excluded to the fullest extent permitted by law.\" ;\n",
      "\t\t:mip_era = \"CMIP6\" ;\n",
      "\t\t:nominal_resolution = \"100 km\" ;\n",
      "\t\t:parent_activity_id = \"CMIP\" ;\n",
      "\t\t:parent_experiment_id = \"historical\" ;\n",
      "\t\t:parent_mip_era = \"CMIP6\" ;\n",
      "\t\t:parent_source_id = \"GFDL-CM4\" ;\n",
      "\t\t:parent_variant_label = \"r1i1p1f1\" ;\n",
      "\t\t:physics_index = 1 ;\n",
      "\t\t:product = \"model-output\" ;\n",
      "\t\t:realization_index = 1 ;\n",
      "\t\t:realm = \"atmos\" ;\n",
      "\t\t:source = \"GFDL-CM4 (2018): \\n\",\n",
      "\t\t\t\"aerosol: interactive\\n\",\n",
      "\t\t\t\"atmos: GFDL-AM4.0.1 (Cubed-sphere (c96) - 1 degree nominal horizontal resolution; 360 x 180 longitude/latitude; 33 levels; top level 1 hPa)\\n\",\n",
      "\t\t\t\"atmosChem: fast chemistry, aerosol only\\n\",\n",
      "\t\t\t\"land: GFDL-LM4.0.1 (1 degree nominal horizontal resolution; 360 x 180 longitude/latitude; 20 levels; bot level 10m); land:Veg:unnamed (dynamic vegetation, dynamic land use); land:Hydro:unnamed (soil water and ice, multi-layer snow, rivers and lakes)\\n\",\n",
      "\t\t\t\"landIce: GFDL-LM4.0.1\\n\",\n",
      "\t\t\t\"ocean: GFDL-OM4p25 (GFDL-MOM6, tripolar - nominal 0.25 deg; 1440 x 1080 longitude/latitude; 75 levels; top grid cell 0-2 m)\\n\",\n",
      "\t\t\t\"ocnBgchem: GFDL-BLINGv2\\n\",\n",
      "\t\t\t\"seaIce: GFDL-SIM4p25 (GFDL-SIS2.0, tripolar - nominal 0.25 deg; 1440 x 1080 longitude/latitude; 5 layers; 5 thickness categories)\\n\",\n",
      "\t\t\t\"(GFDL ID: 2019_0186)\" ;\n",
      "\t\t:source_id = \"GFDL-CM4\" ;\n",
      "\t\t:source_type = \"AOGCM\" ;\n",
      "\t\t:sub_experiment = \"none\" ;\n",
      "\t\t:sub_experiment_id = \"none\" ;\n",
      "\t\t:title = \"NOAA GFDL GFDL-CM4 model output prepared for CMIP6 update of RCP8.5 based on SSP5\" ;\n",
      "\t\t:tracking_id = \"hdl:21.14100/ad8c930c-124f-4b82-98b2-98cc4236ba25\" ;\n",
      "\t\t:variable_id = \"pr\" ;\n",
      "\t\t:variant_info = \"N/A\" ;\n",
      "\t\t:references = \"see further_info_url attribute\" ;\n",
      "\t\t:variant_label = \"r1i1p1f1\" ;\n",
      "\t\t:branch_time_in_parent = 60225. ;\n",
      "\t\t:parent_time_units = \"days since 1850-1-1\" ;\n",
      "\t\t:_SuperblockVersion = 2 ;\n",
      "\t\t:_IsNetcdf4 = 1 ;\n",
      "\t\t:_Format = \"netCDF-4 classic model\" ;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!ncdump -hst '/g/data/oi10/replicas/CMIP6/ScenarioMIP/NOAA-GFDL/GFDL-CM4/ssp585/r1i1p1f1/day/pr/gr1/v20180701/pr_day_GFDL-CM4_ssp585_r1i1p1f1_gr1_20150101-20341231.nc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this case the file is chunked such that  `pr:_ChunkSizes = 1, 180, 288 ;`\n",
    "\n",
    "Here we see that the data is chunked in time, where one chunk is one time-step and all points in lat-lon.\n",
    "\n",
    "![](images/Chunks.png)\n",
    "image source: https://www.unidata.ucar.edu/blogs/developer/en/entry/chunking_data_why_it_matters\n",
    "\n",
    "Consider 2 types of data access\n",
    "1. Accessing a 2D lat-lon slice in time (RHS figure)\n",
    "2. Accessing a time series at a single lat-lon point (LHS figure)\n",
    "\n",
    "With the chunking above, the first type of data access only needs to access a single chunk, while the second type needs to access ALL the chunks of the data array regardless. This dataset will be fastest for 2D lat-lon single time-step data access.\n",
    "\n",
    "In general, even without chunking - when the data is accessed contiguously (by index order) - time is the slowest variable to access, then y, with x being the fastest. With the chunking method of this CMIP6 dataset, time still remains the slowest variable. For more uniform variable access speeds more evenly spaced chunks would be needed, spacing the chunks in time, lat, and lon.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Time how long it takes to load the precipitation data at `time='2015-01-01'` and then time how long it takes to load the data at `lat=0` and `lon=180` (remember to use `method='nearest'` for the latter case). How much difference is there in the different access methods?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.8 ms, sys: 1.88 ms, total: 30.7 ms\n",
      "Wall time: 435 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.DataArray &#x27;pr&#x27; (time: 1, lat: 180, lon: 288)&gt;\n",
       "array([[[1.1679080e-07, 1.1679080e-07, 1.1679080e-07, ...,\n",
       "         1.1679080e-07, 1.1679080e-07, 1.1679080e-07],\n",
       "        [5.6357038e-08, 5.6899808e-08, 5.7449537e-08, ...,\n",
       "         5.4770052e-08, 5.5292201e-08, 5.5821182e-08],\n",
       "        [7.7667160e-08, 7.7346748e-08, 7.7024652e-08, ...,\n",
       "         7.8618250e-08, 7.8302911e-08, 7.7985881e-08],\n",
       "        ...,\n",
       "        [7.0853553e-06, 7.2527428e-06, 7.4210134e-06, ...,\n",
       "         6.5884897e-06, 6.7532287e-06, 6.9188504e-06],\n",
       "        [2.2063125e-05, 2.2134822e-05, 2.2207438e-05, ...,\n",
       "         2.1853495e-05, 2.1922468e-05, 2.1992342e-05],\n",
       "        [3.0045994e-05, 3.0045994e-05, 3.0045994e-05, ...,\n",
       "         3.0045994e-05, 3.0045994e-05, 3.0045994e-05]]], dtype=float32)\n",
       "Coordinates:\n",
       "  * lon      (lon) float64 0.625 1.875 3.125 4.375 ... 355.6 356.9 358.1 359.4\n",
       "  * lat      (lat) float64 -89.5 -88.5 -87.5 -86.5 -85.5 ... 86.5 87.5 88.5 89.5\n",
       "  * time     (time) object 2015-01-01 12:00:00\n",
       "Attributes:\n",
       "    long_name:      Precipitation\n",
       "    units:          kg m-2 s-1\n",
       "    cell_methods:   area: time: mean\n",
       "    cell_measures:  area: areacella\n",
       "    standard_name:  precipitation_flux\n",
       "    interp_method:  conserve_order1\n",
       "    original_name:  pr</pre>"
      ],
      "text/plain": [
       "<xarray.DataArray 'pr' (time: 1, lat: 180, lon: 288)>\n",
       "array([[[1.1679080e-07, 1.1679080e-07, 1.1679080e-07, ...,\n",
       "         1.1679080e-07, 1.1679080e-07, 1.1679080e-07],\n",
       "        [5.6357038e-08, 5.6899808e-08, 5.7449537e-08, ...,\n",
       "         5.4770052e-08, 5.5292201e-08, 5.5821182e-08],\n",
       "        [7.7667160e-08, 7.7346748e-08, 7.7024652e-08, ...,\n",
       "         7.8618250e-08, 7.8302911e-08, 7.7985881e-08],\n",
       "        ...,\n",
       "        [7.0853553e-06, 7.2527428e-06, 7.4210134e-06, ...,\n",
       "         6.5884897e-06, 6.7532287e-06, 6.9188504e-06],\n",
       "        [2.2063125e-05, 2.2134822e-05, 2.2207438e-05, ...,\n",
       "         2.1853495e-05, 2.1922468e-05, 2.1992342e-05],\n",
       "        [3.0045994e-05, 3.0045994e-05, 3.0045994e-05, ...,\n",
       "         3.0045994e-05, 3.0045994e-05, 3.0045994e-05]]], dtype=float32)\n",
       "Coordinates:\n",
       "  * lon      (lon) float64 0.625 1.875 3.125 4.375 ... 355.6 356.9 358.1 359.4\n",
       "  * lat      (lat) float64 -89.5 -88.5 -87.5 -86.5 -85.5 ... 86.5 87.5 88.5 89.5\n",
       "  * time     (time) object 2015-01-01 12:00:00\n",
       "Attributes:\n",
       "    long_name:      Precipitation\n",
       "    units:          kg m-2 s-1\n",
       "    cell_methods:   area: time: mean\n",
       "    cell_measures:  area: areacella\n",
       "    standard_name:  precipitation_flux\n",
       "    interp_method:  conserve_order1\n",
       "    original_name:  pr"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "f_ssp585.pr.sel(time='2015-01-01').load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.5 ms, sys: 2.42 ms, total: 45.9 ms\n",
      "Wall time: 15.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.DataArray &#x27;pr&#x27; (time: 31390)&gt;\n",
       "array([2.1776618e-06, 9.6000194e-06, 5.3295435e-06, ..., 7.7904500e-05,\n",
       "       1.6186357e-05, 1.5706388e-05], dtype=float32)\n",
       "Coordinates:\n",
       "    lon      float64 180.6\n",
       "    lat      float64 0.5\n",
       "  * time     (time) object 2015-01-01 12:00:00 ... 2100-12-31 12:00:00\n",
       "Attributes:\n",
       "    long_name:      Precipitation\n",
       "    units:          kg m-2 s-1\n",
       "    cell_methods:   area: time: mean\n",
       "    cell_measures:  area: areacella\n",
       "    standard_name:  precipitation_flux\n",
       "    interp_method:  conserve_order1\n",
       "    original_name:  pr</pre>"
      ],
      "text/plain": [
       "<xarray.DataArray 'pr' (time: 31390)>\n",
       "array([2.1776618e-06, 9.6000194e-06, 5.3295435e-06, ..., 7.7904500e-05,\n",
       "       1.6186357e-05, 1.5706388e-05], dtype=float32)\n",
       "Coordinates:\n",
       "    lon      float64 180.6\n",
       "    lat      float64 0.5\n",
       "  * time     (time) object 2015-01-01 12:00:00 ... 2100-12-31 12:00:00\n",
       "Attributes:\n",
       "    long_name:      Precipitation\n",
       "    units:          kg m-2 s-1\n",
       "    cell_methods:   area: time: mean\n",
       "    cell_measures:  area: areacella\n",
       "    standard_name:  precipitation_flux\n",
       "    interp_method:  conserve_order1\n",
       "    original_name:  pr"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "f_ssp585.pr.sel(lat=0,lon=180,method='nearest').load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximately the same amount of data took 100x longer to load.\n",
    "\n",
    "The spatial dataset contains 51840 data-points and took order 100ms to load. The time-series dataset has 31390 data-points and took order 10,000 ms to load.\n",
    "\n",
    "Chunking and the ways in which the data is read is important in considering both how you access the data and if you wish to parallelise your code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NetCDF file Chunks versus Dask Chunks\n",
    "\n",
    "Keep in mind, dask chunking is different to chunking of the stored data. As we saw, the stored data is chunked with chunks of size (1,180,288). The Dask array was chunked with size (7300, 180, 288). You can change the chunking in the dask array. In the below example we are specifying that there be 730 chunks in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:    (bnds: 2, lat: 180, lon: 288, time: 31390)\n",
       "Coordinates:\n",
       "  * lon        (lon) float64 0.625 1.875 3.125 4.375 ... 355.6 356.9 358.1 359.4\n",
       "  * lat        (lat) float64 -89.5 -88.5 -87.5 -86.5 ... 86.5 87.5 88.5 89.5\n",
       "  * time       (time) object 2015-01-01 12:00:00 ... 2100-12-31 12:00:00\n",
       "Dimensions without coordinates: bnds\n",
       "Data variables:\n",
       "    lat_bnds   (time, lat, bnds) float64 dask.array&lt;chunksize=(7300, 180, 2), meta=np.ndarray&gt;\n",
       "    lon_bnds   (time, lon, bnds) float64 dask.array&lt;chunksize=(7300, 288, 2), meta=np.ndarray&gt;\n",
       "    pr         (time, lat, lon) float32 dask.array&lt;chunksize=(730, 180, 288), meta=np.ndarray&gt;\n",
       "    time_bnds  (time, bnds) object dask.array&lt;chunksize=(730, 2), meta=np.ndarray&gt;\n",
       "Attributes:\n",
       "    external_variables:     areacella\n",
       "    history:                File was processed by fremetar (GFDL analog of CM...\n",
       "    table_id:               day\n",
       "    activity_id:            ScenarioMIP\n",
       "    branch_method:          standard\n",
       "    branch_time_in_child:   0.0\n",
       "    comment:                &lt;null ref&gt;\n",
       "    contact:                gfdl.climate.model.info@noaa.gov\n",
       "    Conventions:            CF-1.7 CMIP-6.0 UGRID-1.0\n",
       "    creation_date:          2019-03-18T15:13:56Z\n",
       "    data_specs_version:     01.00.27\n",
       "    experiment:             update of RCP8.5 based on SSP5\n",
       "    experiment_id:          ssp585\n",
       "    forcing_index:          1\n",
       "    frequency:              day\n",
       "    further_info_url:       https://furtherinfo.es-doc.org/CMIP6.NOAA-GFDL.GF...\n",
       "    grid:                   atmos data regridded from Cubed-sphere (c96) to 1...\n",
       "    grid_label:             gr1\n",
       "    initialization_index:   1\n",
       "    institution:            National Oceanic and Atmospheric Administration, ...\n",
       "    institution_id:         NOAA-GFDL\n",
       "    license:                CMIP6 model data produced by NOAA-GFDL is license...\n",
       "    mip_era:                CMIP6\n",
       "    nominal_resolution:     100 km\n",
       "    parent_activity_id:     CMIP\n",
       "    parent_experiment_id:   historical\n",
       "    parent_mip_era:         CMIP6\n",
       "    parent_source_id:       GFDL-CM4\n",
       "    parent_variant_label:   r1i1p1f1\n",
       "    physics_index:          1\n",
       "    product:                model-output\n",
       "    realization_index:      1\n",
       "    realm:                  atmos\n",
       "    source:                 GFDL-CM4 (2018): \\naerosol: interactive\\natmos: G...\n",
       "    source_id:              GFDL-CM4\n",
       "    source_type:            AOGCM\n",
       "    sub_experiment:         none\n",
       "    sub_experiment_id:      none\n",
       "    title:                  NOAA GFDL GFDL-CM4 model output prepared for CMIP...\n",
       "    tracking_id:            hdl:21.14100/ad8c930c-124f-4b82-98b2-98cc4236ba25\n",
       "    variable_id:            pr\n",
       "    variant_info:           N/A\n",
       "    references:             see further_info_url attribute\n",
       "    variant_label:          r1i1p1f1\n",
       "    branch_time_in_parent:  60225.0\n",
       "    parent_time_units:      days since 1850-1-1</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (bnds: 2, lat: 180, lon: 288, time: 31390)\n",
       "Coordinates:\n",
       "  * lon        (lon) float64 0.625 1.875 3.125 4.375 ... 355.6 356.9 358.1 359.4\n",
       "  * lat        (lat) float64 -89.5 -88.5 -87.5 -86.5 ... 86.5 87.5 88.5 89.5\n",
       "  * time       (time) object 2015-01-01 12:00:00 ... 2100-12-31 12:00:00\n",
       "Dimensions without coordinates: bnds\n",
       "Data variables:\n",
       "    lat_bnds   (time, lat, bnds) float64 dask.array<chunksize=(7300, 180, 2), meta=np.ndarray>\n",
       "    lon_bnds   (time, lon, bnds) float64 dask.array<chunksize=(7300, 288, 2), meta=np.ndarray>\n",
       "    pr         (time, lat, lon) float32 dask.array<chunksize=(730, 180, 288), meta=np.ndarray>\n",
       "    time_bnds  (time, bnds) object dask.array<chunksize=(730, 2), meta=np.ndarray>\n",
       "Attributes:\n",
       "    external_variables:     areacella\n",
       "    history:                File was processed by fremetar (GFDL analog of CM...\n",
       "    table_id:               day\n",
       "    activity_id:            ScenarioMIP\n",
       "    branch_method:          standard\n",
       "    branch_time_in_child:   0.0\n",
       "    comment:                <null ref>\n",
       "    contact:                gfdl.climate.model.info@noaa.gov\n",
       "    Conventions:            CF-1.7 CMIP-6.0 UGRID-1.0\n",
       "    creation_date:          2019-03-18T15:13:56Z\n",
       "    data_specs_version:     01.00.27\n",
       "    experiment:             update of RCP8.5 based on SSP5\n",
       "    experiment_id:          ssp585\n",
       "    forcing_index:          1\n",
       "    frequency:              day\n",
       "    further_info_url:       https://furtherinfo.es-doc.org/CMIP6.NOAA-GFDL.GF...\n",
       "    grid:                   atmos data regridded from Cubed-sphere (c96) to 1...\n",
       "    grid_label:             gr1\n",
       "    initialization_index:   1\n",
       "    institution:            National Oceanic and Atmospheric Administration, ...\n",
       "    institution_id:         NOAA-GFDL\n",
       "    license:                CMIP6 model data produced by NOAA-GFDL is license...\n",
       "    mip_era:                CMIP6\n",
       "    nominal_resolution:     100 km\n",
       "    parent_activity_id:     CMIP\n",
       "    parent_experiment_id:   historical\n",
       "    parent_mip_era:         CMIP6\n",
       "    parent_source_id:       GFDL-CM4\n",
       "    parent_variant_label:   r1i1p1f1\n",
       "    physics_index:          1\n",
       "    product:                model-output\n",
       "    realization_index:      1\n",
       "    realm:                  atmos\n",
       "    source:                 GFDL-CM4 (2018): \\naerosol: interactive\\natmos: G...\n",
       "    source_id:              GFDL-CM4\n",
       "    source_type:            AOGCM\n",
       "    sub_experiment:         none\n",
       "    sub_experiment_id:      none\n",
       "    title:                  NOAA GFDL GFDL-CM4 model output prepared for CMIP...\n",
       "    tracking_id:            hdl:21.14100/ad8c930c-124f-4b82-98b2-98cc4236ba25\n",
       "    variable_id:            pr\n",
       "    variant_info:           N/A\n",
       "    references:             see further_info_url attribute\n",
       "    variant_label:          r1i1p1f1\n",
       "    branch_time_in_parent:  60225.0\n",
       "    parent_time_units:      days since 1850-1-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_ssp585 = xr.open_mfdataset(path,chunks={'time':730}, combine='by_coords')\n",
    "\n",
    "f_ssp585"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How big do you make your chunks?\n",
    "\n",
    "The rule of thumb for dask chunks is that you should \"create arrays with a minimum chunksize of at least one million elements\":  http://xarray.pydata.org/en/stable/dask.html#chunking-and-performance\n",
    "\n",
    "netCDF4 chunks are often a lot smaller than dask array chunks. The minimum chunksize exists because if you have too many chunks, then queuing of operations when parallising will be slow, and if they are too big computation and memory can be wasted. The default chunks from dask gave us chunks of size: (7300, 180, 288) or nearly 400 million elements so we could try reducing those chunks if needed. The larger the array, the larger the cost of queueing and the larger chunks may be needed.\n",
    "\n",
    "#### IMPORTANT: Whatever dask array chunks you use, make sure they align with the netCDF4 file chunks!!\n",
    "\n",
    "So far our chunks have been in time, and the netCDF4 file is also chunked in time. If we tried to use dask chunks to optimise the time-series loading of data, it will not help! \n",
    "\n",
    "#### Exercise\n",
    "\n",
    "Try it, load the data with chunks size `(31390,180,1)` (i.e. chunked in lon) and name that file `f_bad_chunk`. Try re-loading the time series of pr at `lat=0` and `lon=180` and time how long it takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_bad_chunk = xr.open_mfdataset(path,chunks={'time':31390,'lat':180,'lon':1}, combine='by_coords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.2 ms, sys: 9.91 ms, total: 35.1 ms\n",
      "Wall time: 6.37 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.DataArray &#x27;pr&#x27; (time: 31390)&gt;\n",
       "array([2.1776618e-06, 9.6000194e-06, 5.3295435e-06, ..., 7.7904500e-05,\n",
       "       1.6186357e-05, 1.5706388e-05], dtype=float32)\n",
       "Coordinates:\n",
       "    lon      float64 180.6\n",
       "    lat      float64 0.5\n",
       "  * time     (time) object 2015-01-01 12:00:00 ... 2100-12-31 12:00:00\n",
       "Attributes:\n",
       "    long_name:      Precipitation\n",
       "    units:          kg m-2 s-1\n",
       "    cell_methods:   area: time: mean\n",
       "    cell_measures:  area: areacella\n",
       "    standard_name:  precipitation_flux\n",
       "    interp_method:  conserve_order1\n",
       "    original_name:  pr</pre>"
      ],
      "text/plain": [
       "<xarray.DataArray 'pr' (time: 31390)>\n",
       "array([2.1776618e-06, 9.6000194e-06, 5.3295435e-06, ..., 7.7904500e-05,\n",
       "       1.6186357e-05, 1.5706388e-05], dtype=float32)\n",
       "Coordinates:\n",
       "    lon      float64 180.6\n",
       "    lat      float64 0.5\n",
       "  * time     (time) object 2015-01-01 12:00:00 ... 2100-12-31 12:00:00\n",
       "Attributes:\n",
       "    long_name:      Precipitation\n",
       "    units:          kg m-2 s-1\n",
       "    cell_methods:   area: time: mean\n",
       "    cell_measures:  area: areacella\n",
       "    standard_name:  precipitation_flux\n",
       "    interp_method:  conserve_order1\n",
       "    original_name:  pr"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "f_bad_chunk.pr.sel(lat=0,lon=180,method='nearest').load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we add some extra cores to the computation?\n",
    "\n",
    "You can easily parallelise xarray code using the dask.distributed.Client and dask array calculations will be run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:43603</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>32</li>\n",
       "  <li><b>Memory: </b>68.72 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:43603' processes=8 threads=32, memory=68.72 GB>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "c = Client()\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Try running your previous code for `f_bad_chunk` again loading the time series of pr at `lat=0` and `lon=180` and time how long it takes now that there are 8 workers in the dask cluster.\n",
    "\n",
    "Do the same with the original chunking method of `f_ssp585` and see if there is a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 486 ms, sys: 110 ms, total: 597 ms\n",
      "Wall time: 7.11 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.DataArray &#x27;pr&#x27; (time: 31390)&gt;\n",
       "array([2.1776618e-06, 9.6000194e-06, 5.3295435e-06, ..., 7.7904500e-05,\n",
       "       1.6186357e-05, 1.5706388e-05], dtype=float32)\n",
       "Coordinates:\n",
       "    lon      float64 180.6\n",
       "    lat      float64 0.5\n",
       "  * time     (time) object 2015-01-01 12:00:00 ... 2100-12-31 12:00:00\n",
       "Attributes:\n",
       "    long_name:      Precipitation\n",
       "    units:          kg m-2 s-1\n",
       "    cell_methods:   area: time: mean\n",
       "    cell_measures:  area: areacella\n",
       "    standard_name:  precipitation_flux\n",
       "    interp_method:  conserve_order1\n",
       "    original_name:  pr</pre>"
      ],
      "text/plain": [
       "<xarray.DataArray 'pr' (time: 31390)>\n",
       "array([2.1776618e-06, 9.6000194e-06, 5.3295435e-06, ..., 7.7904500e-05,\n",
       "       1.6186357e-05, 1.5706388e-05], dtype=float32)\n",
       "Coordinates:\n",
       "    lon      float64 180.6\n",
       "    lat      float64 0.5\n",
       "  * time     (time) object 2015-01-01 12:00:00 ... 2100-12-31 12:00:00\n",
       "Attributes:\n",
       "    long_name:      Precipitation\n",
       "    units:          kg m-2 s-1\n",
       "    cell_methods:   area: time: mean\n",
       "    cell_measures:  area: areacella\n",
       "    standard_name:  precipitation_flux\n",
       "    interp_method:  conserve_order1\n",
       "    original_name:  pr"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "f_bad_chunk.pr.sel(lat=0,lon=180,method='nearest').load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 541 ms, sys: 103 ms, total: 644 ms\n",
      "Wall time: 4.37 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.DataArray &#x27;pr&#x27; (time: 31390)&gt;\n",
       "array([2.1776618e-06, 9.6000194e-06, 5.3295435e-06, ..., 7.7904500e-05,\n",
       "       1.6186357e-05, 1.5706388e-05], dtype=float32)\n",
       "Coordinates:\n",
       "    lon      float64 180.6\n",
       "    lat      float64 0.5\n",
       "  * time     (time) object 2015-01-01 12:00:00 ... 2100-12-31 12:00:00\n",
       "Attributes:\n",
       "    long_name:      Precipitation\n",
       "    units:          kg m-2 s-1\n",
       "    cell_methods:   area: time: mean\n",
       "    cell_measures:  area: areacella\n",
       "    standard_name:  precipitation_flux\n",
       "    interp_method:  conserve_order1\n",
       "    original_name:  pr</pre>"
      ],
      "text/plain": [
       "<xarray.DataArray 'pr' (time: 31390)>\n",
       "array([2.1776618e-06, 9.6000194e-06, 5.3295435e-06, ..., 7.7904500e-05,\n",
       "       1.6186357e-05, 1.5706388e-05], dtype=float32)\n",
       "Coordinates:\n",
       "    lon      float64 180.6\n",
       "    lat      float64 0.5\n",
       "  * time     (time) object 2015-01-01 12:00:00 ... 2100-12-31 12:00:00\n",
       "Attributes:\n",
       "    long_name:      Precipitation\n",
       "    units:          kg m-2 s-1\n",
       "    cell_methods:   area: time: mean\n",
       "    cell_measures:  area: areacella\n",
       "    standard_name:  precipitation_flux\n",
       "    interp_method:  conserve_order1\n",
       "    original_name:  pr"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "f_ssp585.pr.sel(lat=0,lon=180,method='nearest').load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poor chunking with dask can make your performance worse!\n",
    "\n",
    "Both the size of the chunks and the alignment of the chunks with the filesystem chunks are imporant to keep in mind when creating dask chunks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "This example shows how to make data chunking with dask. \n",
    "\n",
    "For further information regarding Dask please see: https://docs.dask.org/en/latest/"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
